{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def compute_average_ratings(user_ratings_df):\n",
    "    \"\"\"\n",
    "    Compute the average rating for each dive site.\n",
    "    \"\"\"\n",
    "    avg_ratings = user_ratings_df.groupby(\"dive_site_id\")[\"rating\"].mean().reset_index()\n",
    "    avg_ratings.columns = [\"dive_site_id\", \"average_rating\"]\n",
    "    return avg_ratings\n",
    "\n",
    "\n",
    "def build_user_profile(user_id, user_ratings_df, dive_sites_df):\n",
    "    \"\"\"\n",
    "    Builds a user profile indicating the likelihood of the user liking each cluster.\n",
    "    \"\"\"\n",
    "    # Merge ratings with dive sites to access clusters\n",
    "    merged_df = pd.merge(user_ratings_df, dive_sites_df, left_on=\"dive_site_id\", right_on=\"id\")\n",
    "    \n",
    "    # Filter user's ratings\n",
    "    user_data = merged_df[merged_df[\"user_id\"] == user_id]\n",
    "    \n",
    "    # Calculate average rating per cluster\n",
    "    cluster_preferences = user_data.groupby(\"cluster_x\")[\"rating\"].mean().reset_index()\n",
    "    cluster_preferences.columns = [\"cluster\", \"preference_score\"]\n",
    "    \n",
    "    # Normalize preference scores (optional for consistent scaling)\n",
    "    cluster_preferences[\"preference_score\"] /= cluster_preferences[\"preference_score\"].sum()\n",
    "    \n",
    "    return cluster_preferences.sort_values(by=\"preference_score\", ascending=False)\n",
    "\n",
    "\n",
    "def recommend_from_clusters(user_id, cluster_preferences, user_ratings_df, dive_sites_df, avg_ratings, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommends dive sites based on the user's cluster preferences.\n",
    "    \"\"\"\n",
    "    # Get dive sites the user has already rated\n",
    "    rated_sites = user_ratings_df[user_ratings_df[\"user_id\"] == user_id][\"dive_site_id\"].values\n",
    "    \n",
    "    # Filter dive sites the user hasn't rated\n",
    "    unrated_sites = dive_sites_df[~dive_sites_df[\"id\"].isin(rated_sites)]\n",
    "    \n",
    "    # Merge unrated sites with average ratings\n",
    "    unrated_sites = pd.merge(unrated_sites, avg_ratings, left_on=\"id\", right_on=\"dive_site_id\", how=\"left\")\n",
    "    \n",
    "    # Create recommendations list\n",
    "    recommendations = []\n",
    "    \n",
    "    for _, row in cluster_preferences.iterrows():\n",
    "        cluster = row[\"cluster\"]\n",
    "        # Get dive sites from the current cluster\n",
    "        cluster_sites = unrated_sites[unrated_sites[\"cluster\"] == cluster]\n",
    "        # Sort sites by average rating\n",
    "        cluster_sites = cluster_sites.sort_values(by=\"average_rating\", ascending=False)\n",
    "        recommendations.extend(cluster_sites.to_dict(\"records\"))\n",
    "    \n",
    "    # Return the top N recommendations\n",
    "    return recommendations[:top_n]\n",
    "\n",
    "def is_cluster_in_preferred_clusters(cluster, preferred_clusters):\n",
    "    \"\"\"\n",
    "    Checks if a cluster is in the list of preferred clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    cluster (int): The recommended cluster.\n",
    "    preferred_clusters (list): List of preferred clusters.\n",
    "    \n",
    "    Returns:\n",
    "    bool:True if the cluster exists in the preferred clusters, otherwise False.\n",
    "    \"\"\"\n",
    "    return cluster in ast.literal_eval(preferred_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  user_id                                  preferred_regions  \\\n",
      "10          10       11  ['Ireland', 'Northern Mariana Islands', 'Andam...   \n",
      "\n",
      "   preferred_animals                     preferred_types preferred_clusters  \n",
      "10   [199, 382, 488]  ['Wall', 'Sandy bottom', 'Cavern']             [7, 6]  \n",
      "   Unnamed: 0    id                        title       lat       long  \\\n",
      "0        1908  1908      Dive Magic Orchard Pool  43.58086 -116.24270   \n",
      "1        3140  3129               Flagpole Point  47.56457 -123.01457   \n",
      "2        2611  2606         Loch Low-Minn Quarry  35.48219  -84.50952   \n",
      "3        3712  3706               Blue Cathedral   9.83881  126.16734   \n",
      "4        2817  2809              Circle of Heros  28.05100  -83.00000   \n",
      "5        3079  3068  Manhattan Plaza Health Club  40.75997  -73.99410   \n",
      "6        1946  1946                     The Arch  33.47290 -119.03600   \n",
      "7        1948  1948             Farnsworth Banks  33.50556 -118.77556   \n",
      "8        2319  2313                  La Catedral  38.95109    1.52769   \n",
      "9         814   789    Negro Bar/ Rainbow Bridge  38.67961 -121.18153   \n",
      "\n",
      "                                         description  \\\n",
      "0                                                NaN   \n",
      "1  Flagpole Rock is a popular dive site adjacent ...   \n",
      "2  Loch Low‑Minn is a ten-acre quarry lake in Ath...   \n",
      "3  Siargao’s famous Pacific Ocean dive offered on...   \n",
      "4  12 Military statues are in a circle with chain...   \n",
      "5              One of the best training pools in NYC   \n",
      "6  The Channel Islands offer pristine diving that...   \n",
      "7  Farnsworth Banks is one of Southern California...   \n",
      "8  Maximum depth: 15 meters Minimum level: Open W...   \n",
      "9  Negro Bar is located on the American River. Vi...   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "1  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "2  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "3  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "4  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "5  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "6  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "7  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "8  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "9  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
      "\n",
      "                                                 url  max_depth  \\\n",
      "0  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "1  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "2  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "3  https://www.padi.com/dive-site/philippines/blu...        NaN   \n",
      "4  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "5  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "6  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "7  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "8  https://www.padi.com/dive-site/spain/la-catedr...        NaN   \n",
      "9  https://www.padi.com/dive-site/united-states-o...        NaN   \n",
      "\n",
      "          region  ...                name dive_site_id_y  \\\n",
      "0  United States  ...            ['Pool']            NaN   \n",
      "1  United States  ...        ['Pinnacle']         3129.0   \n",
      "2  United States  ...          ['Quarry']         2606.0   \n",
      "3    Philippines  ...          ['Cavern']         3706.0   \n",
      "4  United States  ...    ['Sandy bottom']            NaN   \n",
      "5  United States  ...            ['Pool']            NaN   \n",
      "6  United States  ...           ['Ocean']         1946.0   \n",
      "7  United States  ...           ['Ocean']         1948.0   \n",
      "8          Spain  ...            ['Cave']            NaN   \n",
      "9  United States  ...  ['Drift', 'River']            NaN   \n",
      "\n",
      "              animal_id cluster     pca_1     pca_2     tsne_1     tsne_2  \\\n",
      "0                   NaN       2 -0.687806 -0.430278 -65.048195 -15.584087   \n",
      "1     [111, 5, 88, 156]       2 -0.505350 -0.345201 -21.546787 -13.587671   \n",
      "2                  [59]       2 -0.658346 -0.422991 -27.243118 -25.264183   \n",
      "3         [402, 7, 326]       2 -0.475933 -0.410149 -42.877026 -14.431067   \n",
      "4                   NaN       2 -0.613030 -0.304526 -23.441994 -18.659958   \n",
      "5                   NaN       2 -0.662482 -0.433021 -64.476616 -14.662665   \n",
      "6  [136, 198, 318, 319]       2 -0.570335 -0.152408 -15.848660  -3.778663   \n",
      "7       [102, 110, 319]       2 -0.544331 -0.108872 -13.885727  -3.966539   \n",
      "8                   NaN       2 -0.635363 -0.402920 -33.358086 -11.236391   \n",
      "9                   NaN       2 -0.623214 -0.226358 -32.953990 -19.623865   \n",
      "\n",
      "   dive_site_id  average_rating  \n",
      "0        1908.0             5.0  \n",
      "1        3129.0             5.0  \n",
      "2        2606.0             5.0  \n",
      "3        3706.0             5.0  \n",
      "4        2809.0             5.0  \n",
      "5        3068.0             5.0  \n",
      "6        1946.0             5.0  \n",
      "7        1948.0             5.0  \n",
      "8        2313.0             5.0  \n",
      "9         789.0             5.0  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "user_ratings_df = pd.read_csv(\"../user_ratings_data.csv\")\n",
    "dive_sites_df = pd.read_csv(\"../dive_sites.csv\")  \n",
    "features = pd.read_csv('../preferences.csv')\n",
    "\n",
    "# Compute average ratings\n",
    "avg_ratings = compute_average_ratings(user_ratings_df)\n",
    "\n",
    "i = int(input(\"Enter the user ID to calculate recommendations for: \"))\n",
    "    \n",
    "ft = features[features['user_id']==i]\n",
    "\n",
    "# Build user profile\n",
    "cluster_preferences = build_user_profile(i, user_ratings_df, dive_sites_df)\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = recommend_from_clusters(i, cluster_preferences, user_ratings_df, dive_sites_df, avg_ratings, top_n=10)\n",
    "    \n",
    "print(ft)\n",
    "print(pd.DataFrame(recommendations[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Basierte Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_average_ratings(user_ratings_df):\n",
    "    \"\"\"\n",
    "    Compute the average rating for each dive site.\n",
    "    \"\"\"\n",
    "    avg_ratings = user_ratings_df.groupby(\"dive_site_id\")[\"rating\"].mean().reset_index()\n",
    "    avg_ratings.columns = [\"dive_site_id\", \"average_rating\"]\n",
    "    return avg_ratings\n",
    "\n",
    "\n",
    "def build_user_profile(user_id, user_ratings_df, dive_sites_df):\n",
    "    \"\"\"\n",
    "    Builds a user profile indicating the likelihood of the user liking each cluster.\n",
    "    \"\"\"\n",
    "    # Merge ratings with dive sites to access clusters\n",
    "    merged_df = pd.merge(user_ratings_df, dive_sites_df, left_on=\"dive_site_id\", right_on=\"id\")\n",
    "    \n",
    "    # Filter user's ratings\n",
    "    user_data = merged_df[merged_df[\"user_id\"] == user_id]\n",
    "    \n",
    "        # Calculate average rating per cluster\n",
    "    cluster_preferences = user_data.groupby(\"cluster_x\")[\"rating\"].mean().reset_index()\n",
    "    cluster_preferences.columns = [\"cluster\", \"preference_score\"]\n",
    "    \n",
    "    # Normalize preference scores (optional for consistent scaling)\n",
    "    cluster_preferences[\"preference_score\"] /= cluster_preferences[\"preference_score\"].sum()\n",
    "    \n",
    "    return cluster_preferences.sort_values(by=\"preference_score\", ascending=False)\n",
    "\n",
    "\n",
    "def recommend_from_clusters_with_sampling(\n",
    "    user_id, cluster_preferences, user_ratings_df, dive_sites_df, avg_ratings, sample_size=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Recommends dive sites based on user's cluster preferences with weighted random sampling.\n",
    "    \"\"\"\n",
    "    # Get dive sites the user has already rated\n",
    "    rated_sites = user_ratings_df[user_ratings_df[\"user_id\"] == user_id][\"dive_site_id\"].values\n",
    "    \n",
    "    # Filter dive sites the user hasn't rated\n",
    "    unrated_sites = dive_sites_df[~dive_sites_df[\"id\"].isin(rated_sites)]\n",
    "    \n",
    "    # Merge unrated sites with average ratings\n",
    "    unrated_sites = pd.merge(unrated_sites, avg_ratings, left_on=\"id\", right_on=\"dive_site_id\", how=\"left\")\n",
    "    \n",
    "    # Perform weighted sampling based on cluster preferences\n",
    "    recommendations = []\n",
    "    for _, row in cluster_preferences.iterrows():\n",
    "        cluster = row[\"cluster\"]\n",
    "        preference_weight = row[\"preference_score\"]\n",
    "        \n",
    "        # Filter dive sites from the current cluster\n",
    "        cluster_sites = unrated_sites[unrated_sites[\"cluster\"] == cluster]\n",
    "        \n",
    "        # Perform weighted sampling\n",
    "        if not cluster_sites.empty:\n",
    "            sampled_sites = cluster_sites.sample(\n",
    "                n=min(len(cluster_sites), int(sample_size * preference_weight)), \n",
    "                weights=\"average_rating\", \n",
    "                replace=False\n",
    "            )\n",
    "            recommendations.extend(sampled_sites.to_dict(\"records\"))\n",
    "    \n",
    "    # Shuffle recommendations for randomness\n",
    "    np.random.shuffle(recommendations)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def recommend_regions_with_sites(recommendations, dive_sites_df, top_n_regions=3, max_sites_per_region=3):\n",
    "    \"\"\"\n",
    "    Groups recommendations by region and selects top regions with dive site recommendations.\n",
    "    \"\"\"\n",
    "    # Group recommendations by region\n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    region_groups = recommendations_df.groupby(\"region\")\n",
    "    \n",
    "    # Calculate region scores (e.g., sum of site ratings in the region)\n",
    "    region_scores = region_groups[\"average_rating\"].sum().reset_index()\n",
    "    region_scores.columns = [\"region\", \"region_score\"]\n",
    "    \n",
    "    # Sort regions by score\n",
    "    top_regions = region_scores.sort_values(by=\"region_score\", ascending=False).head(top_n_regions)\n",
    "    \n",
    "    # Prepare region recommendations\n",
    "    region_recommendations = []\n",
    "    for region in top_regions[\"region\"]:\n",
    "        # Get top dive sites in the region\n",
    "        region_sites = recommendations_df[recommendations_df[\"region\"] == region] \\\n",
    "                       .sort_values(by=\"average_rating\", ascending=False) \\\n",
    "                       .head(max_sites_per_region)\n",
    "        region_recommendations.append({\n",
    "            \"region\": region,\n",
    "            \"top_sites\": region_sites[[\"id\", \"title\", \"name\", \"cluster\", \"average_rating\"]]\n",
    "        })\n",
    "    \n",
    "    return region_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Region: Spain\n",
      "Top Dive Sites:\n",
      "      id                        title                      name  cluster  \\\n",
      "42   779    El Cabrón - The Table Top  ['Cave', 'Reef', 'Wall']        1   \n",
      "43   594                LOS PASADIZOS                  ['Wall']        6   \n",
      "36   591           TERRITORIO CONGRIO         ['Drift', 'Wall']        6   \n",
      "10  1332         Cañones de Vedranell       ['Wall', 'Channel']        6   \n",
      "35  1069  CUEVAS, CT 12 ,CT 17 ,CT 11                  ['Wall']        6   \n",
      "\n",
      "    average_rating  \n",
      "42        4.333333  \n",
      "43        4.000000  \n",
      "36        3.500000  \n",
      "10        3.000000  \n",
      "35        3.000000  \n",
      "\n",
      "Region: Philippines\n",
      "Top Dive Sites:\n",
      "      id                                           title  \\\n",
      "16  3932                                    Tamaraw Reef   \n",
      "6   3041  Aquaventure Helicopter & Boat wreck dive site.   \n",
      "21  3829                                     Balas Balas   \n",
      "47  4167                                         Canyons   \n",
      "9   1655                                          Bangag   \n",
      "\n",
      "                                                 name  cluster  average_rating  \n",
      "16  ['Beach', 'Drift', 'Pinnacle', 'Reef', 'Sandy ...        0        3.500000  \n",
      "6                   ['Wreck', 'Reef', 'Sandy bottom']        5        3.400000  \n",
      "21                                          ['Ocean']        2        3.333333  \n",
      "47              ['Drift', 'Reef', 'Channel', 'Ocean']        1        3.250000  \n",
      "9                                   ['Drift', 'Wall']        6        3.166667  \n",
      "\n",
      "Region: United States\n",
      "Top Dive Sites:\n",
      "      id                         title                name  cluster  \\\n",
      "39  1317                     Blue Hole    ['Lake', 'Wall']        4   \n",
      "14  1092  The Eagle Shipwreck 75-110ft           ['Wreck']        5   \n",
      "17  1593                Pepper's Ferry           ['River']        2   \n",
      "26  2840               Robert Edmister  ['Wreck', 'Ocean']        5   \n",
      "\n",
      "    average_rating  \n",
      "39             5.0  \n",
      "14             4.0  \n",
      "17             4.0  \n",
      "26             3.5  \n",
      "\n",
      "Region: Italy\n",
      "Top Dive Sites:\n",
      "      id              title                        name  cluster  \\\n",
      "27  1749      Punta Arresto                   ['Drift']        2   \n",
      "30  3597     Tana di Gavino                    ['Cave']        2   \n",
      "23  2101  Tonnara del Secco  ['Wall', 'Archaeological']        6   \n",
      "\n",
      "    average_rating  \n",
      "27        4.285714  \n",
      "30        4.000000  \n",
      "23        3.666667  \n",
      "\n",
      "Region: South Africa\n",
      "Top Dive Sites:\n",
      "      id      title      name  cluster  average_rating\n",
      "24  1628  Seal Dive  ['Wall']        6        3.833333\n",
      "38  1876  Cathedral  ['Reef']        1        3.500000\n",
      "\n",
      "Region: Malta\n",
      "Top Dive Sites:\n",
      "      id                      title               name  cluster  \\\n",
      "31   240                      Tug 2  ['Wreck', 'Reef']        5   \n",
      "12  4239  EL ARCO, Cirkewwa (Norte)           ['Reef']        1   \n",
      "\n",
      "    average_rating  \n",
      "31        3.714286  \n",
      "12        3.300000  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "user_ratings_df = pd.read_csv(\"../user_ratings_data.csv\")\n",
    "dive_sites_df = pd.read_csv(\"../dive_sites.csv\")  \n",
    "features = pd.read_csv('../preferences.csv')\n",
    "\n",
    "user_id = int(input(\"Enter User ID: \"))\n",
    "\n",
    "# Schritt 1: Berechne durchschnittliche Ratings\n",
    "avg_ratings = compute_average_ratings(user_ratings_df)\n",
    "\n",
    "# Schritt 2: Erstelle Benutzerprofil\n",
    "cluster_preferences = build_user_profile(user_id, user_ratings_df, dive_sites_df)\n",
    "\n",
    "# Schritt 3: Empfehle Dive Sites mit gewichteter Sampling\n",
    "recommendations = recommend_from_clusters_with_sampling(\n",
    "    user_id, cluster_preferences, user_ratings_df, dive_sites_df, avg_ratings, sample_size=55\n",
    ")\n",
    "\n",
    "# Schritt 4: Finde beste Regionen und ihre Dive Sites\n",
    "region_recommendations = recommend_regions_with_sites(recommendations, dive_sites_df, top_n_regions=6, max_sites_per_region=5)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "for rec in region_recommendations:\n",
    "    print(f\"\\nRegion: {rec['region']}\")\n",
    "    print(\"Top Dive Sites:\")\n",
    "    print(rec[\"top_sites\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
