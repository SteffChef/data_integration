{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>description</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>HMS Maori</td>\n",
       "      <td>35.90250</td>\n",
       "      <td>14.51532</td>\n",
       "      <td>Max Depth: -15mt √ Shore dive √ Beginners Free...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/malta/hms-maori/</td>\n",
       "      <td>None</td>\n",
       "      <td>Malta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>USAT Liberty Shipwreck</td>\n",
       "      <td>-8.27396</td>\n",
       "      <td>115.59307</td>\n",
       "      <td>This is probably the most famous dive site in ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/usat-...</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>Ped</td>\n",
       "      <td>-8.67438</td>\n",
       "      <td>115.51499</td>\n",
       "      <td>Ped dive site consists of a fairly wide and sh...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/ped/</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>Manta Point</td>\n",
       "      <td>-8.79547</td>\n",
       "      <td>115.52553</td>\n",
       "      <td>One of the most famous dive sites in the Bali ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/manta...</td>\n",
       "      <td>65 feet / 20 meters</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>THE HOLE / GREEN BAY CAVES</td>\n",
       "      <td>34.99989</td>\n",
       "      <td>34.06868</td>\n",
       "      <td>Shore entry leading over reefs to a series of ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/cyprus/the-hole...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cyprus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>4391</td>\n",
       "      <td>Lekuan 1, 2, 3</td>\n",
       "      <td>1.59822</td>\n",
       "      <td>124.76752</td>\n",
       "      <td>One of the most popular dive sites on Bunaken ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/lekua...</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>4392</td>\n",
       "      <td>Moc-Che</td>\n",
       "      <td>20.64070</td>\n",
       "      <td>-87.04884</td>\n",
       "      <td>None</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/mexico/moc-che/</td>\n",
       "      <td>None</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>4393</td>\n",
       "      <td>Fish Market</td>\n",
       "      <td>20.81187</td>\n",
       "      <td>-86.88260</td>\n",
       "      <td>Shallow reef, FULL of fish. 30 ft maximum dept...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/mexico/fish-mar...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>4394</td>\n",
       "      <td>The Zenobia Wreck</td>\n",
       "      <td>34.88500</td>\n",
       "      <td>33.74000</td>\n",
       "      <td>The Zenobia Wreck is one of the top ten wreck ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/cyprus/the-zeno...</td>\n",
       "      <td>137 feet / 42 meters</td>\n",
       "      <td>Cyprus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>4395</td>\n",
       "      <td>18th Palm</td>\n",
       "      <td>12.13785</td>\n",
       "      <td>-68.27659</td>\n",
       "      <td>House reef of Plaza Beach &amp; Dive Resort and To...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/bonaire/18th-palm/</td>\n",
       "      <td>None</td>\n",
       "      <td>Bonaire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4395 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       title       lat       long  \\\n",
       "28       1                   HMS Maori  35.90250   14.51532   \n",
       "29       2      USAT Liberty Shipwreck  -8.27396  115.59307   \n",
       "30       3                         Ped  -8.67438  115.51499   \n",
       "31       4                 Manta Point  -8.79547  115.52553   \n",
       "25       5  THE HOLE / GREEN BAY CAVES  34.99989   34.06868   \n",
       "...    ...                         ...       ...        ...   \n",
       "4390  4391              Lekuan 1, 2, 3   1.59822  124.76752   \n",
       "4391  4392                     Moc-Che  20.64070  -87.04884   \n",
       "4392  4393                 Fish Market  20.81187  -86.88260   \n",
       "4393  4394           The Zenobia Wreck  34.88500   33.74000   \n",
       "4394  4395                   18th Palm  12.13785  -68.27659   \n",
       "\n",
       "                                            description  \\\n",
       "28    Max Depth: -15mt √ Shore dive √ Beginners Free...   \n",
       "29    This is probably the most famous dive site in ...   \n",
       "30    Ped dive site consists of a fairly wide and sh...   \n",
       "31    One of the most famous dive sites in the Bali ...   \n",
       "25    Shore entry leading over reefs to a series of ...   \n",
       "...                                                 ...   \n",
       "4390  One of the most popular dive sites on Bunaken ...   \n",
       "4391                                               None   \n",
       "4392  Shallow reef, FULL of fish. 30 ft maximum dept...   \n",
       "4393  The Zenobia Wreck is one of the top ten wreck ...   \n",
       "4394  House reef of Plaza Beach & Dive Resort and To...   \n",
       "\n",
       "                                              image_url  \\\n",
       "28    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "29    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "30    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "31    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "25    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "...                                                 ...   \n",
       "4390  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4391  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4392  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4393  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4394  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "\n",
       "                                                    url             max_depth  \\\n",
       "28      https://www.padi.com/dive-site/malta/hms-maori/                  None   \n",
       "29    https://www.padi.com/dive-site/indonesia/usat-...                  None   \n",
       "30        https://www.padi.com/dive-site/indonesia/ped/                  None   \n",
       "31    https://www.padi.com/dive-site/indonesia/manta...   65 feet / 20 meters   \n",
       "25    https://www.padi.com/dive-site/cyprus/the-hole...                  None   \n",
       "...                                                 ...                   ...   \n",
       "4390  https://www.padi.com/dive-site/indonesia/lekua...                  None   \n",
       "4391     https://www.padi.com/dive-site/mexico/moc-che/                  None   \n",
       "4392  https://www.padi.com/dive-site/mexico/fish-mar...                  None   \n",
       "4393  https://www.padi.com/dive-site/cyprus/the-zeno...  137 feet / 42 meters   \n",
       "4394  https://www.padi.com/dive-site/bonaire/18th-palm/                  None   \n",
       "\n",
       "         region  \n",
       "28        Malta  \n",
       "29    Indonesia  \n",
       "30    Indonesia  \n",
       "31    Indonesia  \n",
       "25       Cyprus  \n",
       "...         ...  \n",
       "4390  Indonesia  \n",
       "4391     Mexico  \n",
       "4392     Mexico  \n",
       "4393     Cyprus  \n",
       "4394    Bonaire  \n",
       "\n",
       "[4395 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import copy\n",
    "\n",
    "# Connection string\n",
    "connection_string = \"postgresql://postgres.svsobttfvdpdxpiwjeqg:z36ow70ANRJB5GHa@aws-0-eu-central-1.pooler.supabase.com:6543/postgres\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Load tables from the database\n",
    "dive_sites = pd.read_sql(\"SELECT * FROM dive_site\", con=engine)\n",
    "dive_site_ratings = pd.read_sql(\"SELECT * FROM dive_site_rating\", con=engine)\n",
    "occurrences = pd.read_sql(\"SELECT * FROM occurrence\", con=engine)\n",
    "animals = pd.read_sql(\"SELECT * FROM animal\", con=engine)\n",
    "animals_ratings = pd.read_sql(\"SELECT * FROM animal_rating\", con=engine)\n",
    "categories = pd.read_sql(\"SELECT * FROM dive_site_category\", con=engine)\n",
    "categories_per_dive_site = pd.read_sql(\"SELECT * FROM categories_per_dive_site\", con=engine)\n",
    "user = pd.read_sql(\"SELECT * FROM user\", con=engine)\n",
    "alembic_version = pd.read_sql(\"SELECT * FROM alembic_version\", con=engine)\n",
    "\n",
    "# sort the dive sites by the id\n",
    "dive_sites = dive_sites.sort_values(by='id')\n",
    "dive_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dive_site_id</th>\n",
       "      <th>animal_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21803</th>\n",
       "      <td>21856</td>\n",
       "      <td>4395</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21804</th>\n",
       "      <td>21857</td>\n",
       "      <td>4395</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21805</th>\n",
       "      <td>21858</td>\n",
       "      <td>4395</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21806</th>\n",
       "      <td>21859</td>\n",
       "      <td>4395</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21807</th>\n",
       "      <td>21860</td>\n",
       "      <td>4395</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21808 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  dive_site_id  animal_id\n",
       "0          1             1          1\n",
       "1          2             1          2\n",
       "2          3             1          3\n",
       "3          4             1          4\n",
       "4          5             1          5\n",
       "...      ...           ...        ...\n",
       "21803  21856          4395         51\n",
       "21804  21857          4395         92\n",
       "21805  21858          4395          2\n",
       "21806  21859          4395         37\n",
       "21807  21860          4395         74\n",
       "\n",
       "[21808 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dive_site_id</th>\n",
       "      <th>dive_site_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8553</th>\n",
       "      <td>4392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8554</th>\n",
       "      <td>4393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>4394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556</th>\n",
       "      <td>4394</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8557</th>\n",
       "      <td>4395</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dive_site_id  dive_site_category_id\n",
       "0                1                      1\n",
       "1                1                      2\n",
       "2                2                      1\n",
       "3                2                      3\n",
       "4                2                      4\n",
       "...            ...                    ...\n",
       "8553          4392                      2\n",
       "8554          4393                      2\n",
       "8555          4394                      1\n",
       "8556          4394                     10\n",
       "8557          4395                      3\n",
       "\n",
       "[8558 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_per_dive_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Fjord</td>\n",
       "      <td>https://www.divingsquad.com/wp-content/uploads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>Muck</td>\n",
       "      <td>https://murexresorts.com/wp-content/uploads/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>Sea Loch</td>\n",
       "      <td>https://meanderapparel.com/cdn/shop/articles/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>Spring</td>\n",
       "      <td>https://imgds360live.s3.amazonaws.com/storefro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Pool</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Archaeological</td>\n",
       "      <td>https://marineprotectedareas.noaa.gov/toolkit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>Quarry</td>\n",
       "      <td>https://images.downeast.com/wp-content/uploads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>Pinnacle</td>\n",
       "      <td>https://go2similan.com/wp-content/uploads/2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>Cavern</td>\n",
       "      <td>https://aquaworld.com.mx/uploads/0000/1/2023/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>River</td>\n",
       "      <td>https://www.macssports.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Sandy bottom</td>\n",
       "      <td>https://images.pond5.com/group-scuba-divers-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>Lake</td>\n",
       "      <td>https://tahoequarterly.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>https://media.istockphoto.com/id/484092196/de/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>Channel</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Cave</td>\n",
       "      <td>https://www.scubadiving.com/sites/default/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Drift</td>\n",
       "      <td>https://www.deeperblue.com/wp-content/uploads/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Wall</td>\n",
       "      <td>https://originaldiving.d3r.site/images/spotlig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>Beach</td>\n",
       "      <td>https://dtmag.com/wp-content/uploads/2003/05/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>Reef</td>\n",
       "      <td>https://www.zubludiving.com/images/Indonesia/W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>Wreck</td>\n",
       "      <td>https://res.cloudinary.com/padi/image/upload/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id            name                                          image_url\n",
       "0   20           Fjord  https://www.divingsquad.com/wp-content/uploads...\n",
       "1   18            Muck  https://murexresorts.com/wp-content/uploads/20...\n",
       "2   19        Sea Loch  https://meanderapparel.com/cdn/shop/articles/r...\n",
       "3   17          Spring  https://imgds360live.s3.amazonaws.com/storefro...\n",
       "4   16            Pool  https://encrypted-tbn0.gstatic.com/images?q=tb...\n",
       "5   15  Archaeological  https://marineprotectedareas.noaa.gov/toolkit/...\n",
       "6   14          Quarry  https://images.downeast.com/wp-content/uploads...\n",
       "7   13        Pinnacle  https://go2similan.com/wp-content/uploads/2021...\n",
       "8   12          Cavern  https://aquaworld.com.mx/uploads/0000/1/2023/0...\n",
       "9   11           River  https://www.macssports.com/wp-content/uploads/...\n",
       "10  10    Sandy bottom  https://images.pond5.com/group-scuba-divers-di...\n",
       "11   9            Lake  https://tahoequarterly.com/wp-content/uploads/...\n",
       "12   8           Ocean  https://media.istockphoto.com/id/484092196/de/...\n",
       "13   7         Channel  https://encrypted-tbn0.gstatic.com/images?q=tb...\n",
       "14   6            Cave  https://www.scubadiving.com/sites/default/file...\n",
       "15   5           Drift  https://www.deeperblue.com/wp-content/uploads/...\n",
       "16   4            Wall  https://originaldiving.d3r.site/images/spotlig...\n",
       "17   3           Beach  https://dtmag.com/wp-content/uploads/2003/05/s...\n",
       "18   2            Reef  https://www.zubludiving.com/images/Indonesia/W...\n",
       "19   1           Wreck  https://res.cloudinary.com/padi/image/upload/f..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>Spider Crab</td>\n",
       "      <td>https://i.ytimg.com/vi/knh7lQFWnnw/hqdefault.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>Ribbon Eel</td>\n",
       "      <td>https://i0.wp.com/www.australiangeographic.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>Chondrichthyes</td>\n",
       "      <td>https://cdn.oceanographicmagazine.com/wp-conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121</td>\n",
       "      <td>Jellyfish</td>\n",
       "      <td>https://s3.eu-west-1.amazonaws.com/media.mcsuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Moray Eel</td>\n",
       "      <td>https://blog.mares.com/wp-content/uploads/2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>498</td>\n",
       "      <td>Heteractis Anemones</td>\n",
       "      <td>https://as1.ftcdn.net/v2/jpg/01/65/57/74/1000_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>499</td>\n",
       "      <td>Rocketfishes</td>\n",
       "      <td>https://www.montereybayaquarium.org/globalasse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>500</td>\n",
       "      <td>Serpent Eel</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>254</td>\n",
       "      <td>Tree Dorids</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>446</td>\n",
       "      <td>Desmacidids</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                 name  \\\n",
       "0    149          Spider Crab   \n",
       "1    325           Ribbon Eel   \n",
       "2     83       Chondrichthyes   \n",
       "3    121            Jellyfish   \n",
       "4      1            Moray Eel   \n",
       "..   ...                  ...   \n",
       "495  498  Heteractis Anemones   \n",
       "496  499         Rocketfishes   \n",
       "497  500          Serpent Eel   \n",
       "498  254          Tree Dorids   \n",
       "499  446          Desmacidids   \n",
       "\n",
       "                                             image_url  \n",
       "0     https://i.ytimg.com/vi/knh7lQFWnnw/hqdefault.jpg  \n",
       "1    https://i0.wp.com/www.australiangeographic.com...  \n",
       "2    https://cdn.oceanographicmagazine.com/wp-conte...  \n",
       "3    https://s3.eu-west-1.amazonaws.com/media.mcsuk...  \n",
       "4    https://blog.mares.com/wp-content/uploads/2017...  \n",
       "..                                                 ...  \n",
       "495  https://as1.ftcdn.net/v2/jpg/01/65/57/74/1000_...  \n",
       "496  https://www.montereybayaquarium.org/globalasse...  \n",
       "497  https://upload.wikimedia.org/wikipedia/commons...  \n",
       "498  https://encrypted-tbn0.gstatic.com/images?q=tb...  \n",
       "499  https://encrypted-tbn0.gstatic.com/images?q=tb...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of animals:  500\n",
      "Number of unique animal names:  500\n"
     ]
    }
   ],
   "source": [
    "# Analyse if animal names are unique\n",
    "animal_names = animals['name'].values\n",
    "unique_animal_names = np.unique(animal_names)\n",
    "print(\"Number of animals: \", len(animal_names))\n",
    "print(\"Number of unique animal names: \", len(unique_animal_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "True     4392\n",
       "False       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze categotires_per_dive_site: How many dive sites have no categories? 3/4392\n",
    "# check if every dive site id appears in the categories_per_dive_site table\n",
    "dive_sites['id'].isin(categories_per_dive_site['dive_site_id']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.48282138794084184)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many dive sites have no description? -> 12,7 % of the dive sites have no description\n",
    "dive_sites['description'].isnull().sum() / len(dive_sites)\n",
    "\n",
    "#how many dive sites have no max_depth? -> 50 % of the dive sites have no max_depth\n",
    "dive_sites['max_depth'].isnull().sum() / len(dive_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4395.000000</td>\n",
       "      <td>4395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.856706</td>\n",
       "      <td>20.518053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.578385</td>\n",
       "      <td>79.242567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-45.773550</td>\n",
       "      <td>-169.935680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.567945</td>\n",
       "      <td>-59.634820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.450980</td>\n",
       "      <td>14.285760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.009065</td>\n",
       "      <td>99.811555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.639000</td>\n",
       "      <td>179.934040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lat         long\n",
       "count  4395.000000  4395.000000\n",
       "mean     19.856706    20.518053\n",
       "std      22.578385    79.242567\n",
       "min     -45.773550  -169.935680\n",
       "25%       8.567945   -59.634820\n",
       "50%      20.450980    14.285760\n",
       "75%      38.009065    99.811555\n",
       "max      69.639000   179.934040"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the max and min of latitude and longitude\n",
    "dive_sites[['lat', 'long']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a vector-like representation for each dive-site:\n",
    "- geodata latitude, longitude\n",
    "- category\n",
    "- animals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector like representation for each dive site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites[animal_name] = 0\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites['occurences'] = ''\n",
      "C:\\Users\\pietv\\AppData\\Local\\Temp\\ipykernel_5628\\3372933297.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  converted_dive_sites['categories'] = ''\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>description</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>region</th>\n",
       "      <th>Fjord</th>\n",
       "      <th>...</th>\n",
       "      <th>Tautog</th>\n",
       "      <th>Sea Raven</th>\n",
       "      <th>Tripplefins</th>\n",
       "      <th>Heteractis Anemones</th>\n",
       "      <th>Rocketfishes</th>\n",
       "      <th>Serpent Eel</th>\n",
       "      <th>Tree Dorids</th>\n",
       "      <th>Desmacidids</th>\n",
       "      <th>occurences</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>HMS Maori</td>\n",
       "      <td>35.90250</td>\n",
       "      <td>14.51532</td>\n",
       "      <td>Max Depth: -15mt √ Shore dive √ Beginners Free...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/malta/hms-maori/</td>\n",
       "      <td>None</td>\n",
       "      <td>Malta</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moray Eel, Seahorse Family, Flounder, Eagle Ra...</td>\n",
       "      <td>Wreck, Reef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>USAT Liberty Shipwreck</td>\n",
       "      <td>-8.27396</td>\n",
       "      <td>115.59307</td>\n",
       "      <td>This is probably the most famous dive site in ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/usat-...</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sea Turtle, Jackfish, Grouper, Dorid Nudibranc...</td>\n",
       "      <td>Wreck, Beach, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>Ped</td>\n",
       "      <td>-8.67438</td>\n",
       "      <td>115.51499</td>\n",
       "      <td>Ped dive site consists of a fairly wide and sh...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/ped/</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorpionfish, Pufferfish, Boxfish, Damselfish,...</td>\n",
       "      <td>Drift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>Manta Point</td>\n",
       "      <td>-8.79547</td>\n",
       "      <td>115.52553</td>\n",
       "      <td>One of the most famous dive sites in the Bali ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/manta...</td>\n",
       "      <td>65 feet / 20 meters</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Eagle Ray, Manta Ray, Stingray, Requiem Sharks...</td>\n",
       "      <td>Reef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>THE HOLE / GREEN BAY CAVES</td>\n",
       "      <td>34.99989</td>\n",
       "      <td>34.06868</td>\n",
       "      <td>Shore entry leading over reefs to a series of ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/cyprus/the-hole...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Squirrelfish, Fireworms, Seahorse Family, Leat...</td>\n",
       "      <td>Cave, Reef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>4391</td>\n",
       "      <td>Lekuan 1, 2, 3</td>\n",
       "      <td>1.59822</td>\n",
       "      <td>124.76752</td>\n",
       "      <td>One of the most popular dive sites on Bunaken ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/indonesia/lekua...</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tigerfish, Wrasse, Parrotfish, Trumpetfish, Da...</td>\n",
       "      <td>Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>4392</td>\n",
       "      <td>Moc-Che</td>\n",
       "      <td>20.64070</td>\n",
       "      <td>-87.04884</td>\n",
       "      <td>None</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/mexico/moc-che/</td>\n",
       "      <td>None</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Remora, Leatherjacket Fish, Swimming Crabs, Ti...</td>\n",
       "      <td>Drift, Reef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>4393</td>\n",
       "      <td>Fish Market</td>\n",
       "      <td>20.81187</td>\n",
       "      <td>-86.88260</td>\n",
       "      <td>Shallow reef, FULL of fish. 30 ft maximum dept...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/mexico/fish-mar...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Reef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>4394</td>\n",
       "      <td>The Zenobia Wreck</td>\n",
       "      <td>34.88500</td>\n",
       "      <td>33.74000</td>\n",
       "      <td>The Zenobia Wreck is one of the top ten wreck ...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/cyprus/the-zeno...</td>\n",
       "      <td>137 feet / 42 meters</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nudibranch, Sea Urchin</td>\n",
       "      <td>Wreck, Sandy bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>4395</td>\n",
       "      <td>18th Palm</td>\n",
       "      <td>12.13785</td>\n",
       "      <td>-68.27659</td>\n",
       "      <td>House reef of Plaza Beach &amp; Dive Resort and To...</td>\n",
       "      <td>https://d2p1cf6997m1ir.cloudfront.net/media/th...</td>\n",
       "      <td>https://www.padi.com/dive-site/bonaire/18th-palm/</td>\n",
       "      <td>None</td>\n",
       "      <td>Bonaire</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Grunts, Octopus, Surgeonfish, Squid, Moon Jell...</td>\n",
       "      <td>Beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4395 rows × 533 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       title       lat       long  \\\n",
       "28       1                   HMS Maori  35.90250   14.51532   \n",
       "29       2      USAT Liberty Shipwreck  -8.27396  115.59307   \n",
       "30       3                         Ped  -8.67438  115.51499   \n",
       "31       4                 Manta Point  -8.79547  115.52553   \n",
       "25       5  THE HOLE / GREEN BAY CAVES  34.99989   34.06868   \n",
       "...    ...                         ...       ...        ...   \n",
       "4390  4391              Lekuan 1, 2, 3   1.59822  124.76752   \n",
       "4391  4392                     Moc-Che  20.64070  -87.04884   \n",
       "4392  4393                 Fish Market  20.81187  -86.88260   \n",
       "4393  4394           The Zenobia Wreck  34.88500   33.74000   \n",
       "4394  4395                   18th Palm  12.13785  -68.27659   \n",
       "\n",
       "                                            description  \\\n",
       "28    Max Depth: -15mt √ Shore dive √ Beginners Free...   \n",
       "29    This is probably the most famous dive site in ...   \n",
       "30    Ped dive site consists of a fairly wide and sh...   \n",
       "31    One of the most famous dive sites in the Bali ...   \n",
       "25    Shore entry leading over reefs to a series of ...   \n",
       "...                                                 ...   \n",
       "4390  One of the most popular dive sites on Bunaken ...   \n",
       "4391                                               None   \n",
       "4392  Shallow reef, FULL of fish. 30 ft maximum dept...   \n",
       "4393  The Zenobia Wreck is one of the top ten wreck ...   \n",
       "4394  House reef of Plaza Beach & Dive Resort and To...   \n",
       "\n",
       "                                              image_url  \\\n",
       "28    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "29    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "30    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "31    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "25    https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "...                                                 ...   \n",
       "4390  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4391  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4392  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4393  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "4394  https://d2p1cf6997m1ir.cloudfront.net/media/th...   \n",
       "\n",
       "                                                    url             max_depth  \\\n",
       "28      https://www.padi.com/dive-site/malta/hms-maori/                  None   \n",
       "29    https://www.padi.com/dive-site/indonesia/usat-...                  None   \n",
       "30        https://www.padi.com/dive-site/indonesia/ped/                  None   \n",
       "31    https://www.padi.com/dive-site/indonesia/manta...   65 feet / 20 meters   \n",
       "25    https://www.padi.com/dive-site/cyprus/the-hole...                  None   \n",
       "...                                                 ...                   ...   \n",
       "4390  https://www.padi.com/dive-site/indonesia/lekua...                  None   \n",
       "4391     https://www.padi.com/dive-site/mexico/moc-che/                  None   \n",
       "4392  https://www.padi.com/dive-site/mexico/fish-mar...                  None   \n",
       "4393  https://www.padi.com/dive-site/cyprus/the-zeno...  137 feet / 42 meters   \n",
       "4394  https://www.padi.com/dive-site/bonaire/18th-palm/                  None   \n",
       "\n",
       "         region  Fjord  ...  Tautog  Sea Raven  Tripplefins  \\\n",
       "28        Malta      0  ...       0          0            0   \n",
       "29    Indonesia      0  ...       0          0            0   \n",
       "30    Indonesia      0  ...       0          0            0   \n",
       "31    Indonesia      0  ...       0          0            0   \n",
       "25       Cyprus      0  ...       0          0            0   \n",
       "...         ...    ...  ...     ...        ...          ...   \n",
       "4390  Indonesia      0  ...       0          0            0   \n",
       "4391     Mexico      0  ...       0          0            0   \n",
       "4392     Mexico      0  ...       0          0            0   \n",
       "4393     Cyprus      0  ...       0          0            0   \n",
       "4394    Bonaire      0  ...       0          0            0   \n",
       "\n",
       "      Heteractis Anemones  Rocketfishes  Serpent Eel  Tree Dorids  \\\n",
       "28                      0             0            0            0   \n",
       "29                      0             0            0            0   \n",
       "30                      0             0            0            0   \n",
       "31                      0             0            0            0   \n",
       "25                      0             0            0            0   \n",
       "...                   ...           ...          ...          ...   \n",
       "4390                    0             0            0            0   \n",
       "4391                    0             0            0            0   \n",
       "4392                    0             0            0            0   \n",
       "4393                    0             0            0            0   \n",
       "4394                    0             0            0            0   \n",
       "\n",
       "      Desmacidids                                         occurences  \\\n",
       "28              0  Moray Eel, Seahorse Family, Flounder, Eagle Ra...   \n",
       "29              0  Sea Turtle, Jackfish, Grouper, Dorid Nudibranc...   \n",
       "30              0  Scorpionfish, Pufferfish, Boxfish, Damselfish,...   \n",
       "31              0  Eagle Ray, Manta Ray, Stingray, Requiem Sharks...   \n",
       "25              0  Squirrelfish, Fireworms, Seahorse Family, Leat...   \n",
       "...           ...                                                ...   \n",
       "4390            0  Tigerfish, Wrasse, Parrotfish, Trumpetfish, Da...   \n",
       "4391            0  Remora, Leatherjacket Fish, Swimming Crabs, Ti...   \n",
       "4392            0                                                      \n",
       "4393            0                             Nudibranch, Sea Urchin   \n",
       "4394            0  Grunts, Octopus, Surgeonfish, Squid, Moon Jell...   \n",
       "\n",
       "               categories  \n",
       "28            Wreck, Reef  \n",
       "29     Wreck, Beach, Wall  \n",
       "30                  Drift  \n",
       "31                   Reef  \n",
       "25             Cave, Reef  \n",
       "...                   ...  \n",
       "4390           Reef, Wall  \n",
       "4391          Drift, Reef  \n",
       "4392                 Reef  \n",
       "4393  Wreck, Sandy bottom  \n",
       "4394                Beach  \n",
       "\n",
       "[4395 rows x 533 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's generate a copy for the current dive sites dataframe\n",
    "converted_dive_sites = copy.deepcopy(dive_sites)    \n",
    "\n",
    "# for each category, we generate a new column (indicator if category is present in the list of genres)\n",
    "for cat_id in categories['id']:\n",
    "    # create a new column for the current category\n",
    "    category_name = categories.loc[categories['id'] == cat_id, 'name'].values[0]\n",
    "    converted_dive_sites[category_name] = 0\n",
    "\n",
    "    # iterate over all rows\n",
    "    for index, row in converted_dive_sites.iterrows():\n",
    "        # get a list of all dive_site_category_ids for the current dive_site_id\n",
    "        list_of_cat_ids = list(categories_per_dive_site[categories_per_dive_site['dive_site_id'] == row['id']]['dive_site_category_id'])\n",
    "        # check if the current cat_id in the list of categories for the current dive_site_id\n",
    "        if cat_id in list_of_cat_ids:\n",
    "            converted_dive_sites.at[index, category_name] = 1\n",
    "\n",
    "# Scale lat and long to be between 0 and 1 with a MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "converted_dive_sites[['lat_scaled', 'long_scaled']] = scaler.fit_transform(converted_dive_sites[['lat', 'long']])\n",
    "\n",
    "\n",
    "# Initialize animal feature columns\n",
    "for animal_name in animals['name']:\n",
    "    converted_dive_sites[animal_name] = 0\n",
    "\n",
    "# Populate the animal feature columns\n",
    "for index, row in converted_dive_sites.iterrows():\n",
    "    dive_site_id = row['id']\n",
    "    animal_ids = occurrences[occurrences['dive_site_id'] == dive_site_id]['animal_id'].values   # get all animal_ids for the current dive_site_id\n",
    "    for animal_id in animal_ids:\n",
    "        animal_name = animals[animals['id'] == animal_id]['name'].values[0]\n",
    "        converted_dive_sites.at[index, animal_name] = 1\n",
    "\n",
    "# START\n",
    "#  The following is just for the examples in the end, delete if not needed:\n",
    "\n",
    "# add a new column 'occurences' to the converted_dive_sites dataframe\n",
    "converted_dive_sites['occurences'] = ''\n",
    "for index, row in converted_dive_sites.iterrows():\n",
    "    dive_site_id = row['id']\n",
    "    # get all animal names for the current dive_site_id\n",
    "    animal_ids = occurrences[occurrences['dive_site_id'] == dive_site_id]['animal_id'].values\n",
    "    animal_names = []\n",
    "    for animal_id in animal_ids:\n",
    "        animal_name = animals[animals['id'] == animal_id]['name'].values[0]\n",
    "        animal_names.append(animal_name)\n",
    "\n",
    "    animal_names = ', '.join(animal_names)\n",
    "    converted_dive_sites.at[index, 'occurences'] = animal_names\n",
    "\n",
    "# add a new column 'categories' to the converted_dive_sites dataframe\n",
    "converted_dive_sites['categories'] = ''\n",
    "for index, row in converted_dive_sites.iterrows():\n",
    "    dive_site_id = row['id']\n",
    "    # get all category names for the current dive_site_id\n",
    "    category_ids = categories_per_dive_site[categories_per_dive_site['dive_site_id'] == dive_site_id]['dive_site_category_id'].values\n",
    "    category_names = []\n",
    "    for category_id in category_ids:\n",
    "        category_name = categories[categories['id'] == category_id]['name'].values[0]\n",
    "        category_names.append(category_name)\n",
    "\n",
    "    category_names = ', '.join(category_names)\n",
    "    converted_dive_sites.at[index, 'categories'] = category_names\n",
    "\n",
    "\n",
    "# END\n",
    "\n",
    "\n",
    "# sort converted_dive_sites by id \n",
    "converted_dive_sites = converted_dive_sites.sort_values(by='id')\n",
    "converted_dive_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moray Eel', 'Seahorse Family', 'Flounder', 'Eagle Ray', 'Sea Anemone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moray Eel</th>\n",
       "      <th>Seahorse Family</th>\n",
       "      <th>Flounder</th>\n",
       "      <th>Eagle Ray</th>\n",
       "      <th>Sea Anemone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Moray Eel  Seahorse Family  Flounder  Eagle Ray  Sea Anemone\n",
       "28          1                1         1          1            1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick Test\n",
    "\n",
    "# Dive site 1 has the following animals\n",
    "animal_ids_in_dive_site_1 = occurrences[occurrences['dive_site_id'] == 1][\"animal_id\"].tolist()\n",
    "\n",
    "# Get the names of the animals in animal_ids_in_dive_site_1\n",
    "animal_names_in_dive_site_1 = []\n",
    "for animal_id in animal_ids_in_dive_site_1:\n",
    "    animal_name = animals[animals['id'] == animal_id]['name'].values[0]\n",
    "    animal_names_in_dive_site_1.append(animal_name)\n",
    "\n",
    "print(animal_names_in_dive_site_1)\n",
    "\n",
    "# Check if the columns with an animal_name included in animal_names_in_dive_site_1 are set to 1 - the rest should be 0\n",
    "assert converted_dive_sites.loc[converted_dive_sites['id'] == 1, animal_names_in_dive_site_1].values.all() == 1\n",
    "assert converted_dive_sites.loc[converted_dive_sites['id'] == 1, ~converted_dive_sites.columns.isin(animal_names_in_dive_site_1)].values.all() == 0\n",
    "\n",
    "converted_dive_sites.loc[converted_dive_sites['id'] == 1, animal_names_in_dive_site_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Item Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "def get_cosine_similarity(x, y):\n",
    "    \n",
    "    numerator = np.dot(x,y)\n",
    "    denominator = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "\n",
    "    # sanity check: x and y must be non-zero vectors\n",
    "    if denominator > 0:\n",
    "        sim = numerator / denominator\n",
    "    else:\n",
    "        raise Exception(\"The cosine similarity is not defined for vectors containing only zeros!\")\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1         28\n",
       "2         29\n",
       "3         30\n",
       "4         31\n",
       "5         25\n",
       "        ... \n",
       "4391    4390\n",
       "4392    4391\n",
       "4393    4392\n",
       "4394    4393\n",
       "4395    4394\n",
       "Length: 4395, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map dive site id to their corresponding row indices in the DataFrame\n",
    "# benefit: Fast Lookup\n",
    "dive_sites_ids = converted_dive_sites['id']\n",
    "indices = pd.Series(converted_dive_sites.index, index=converted_dive_sites['id'])\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dive_site_categories_vector(index):\n",
    "    \"\"\"This function returns a vector representation of categories of the dive site with the given dive_site_id\"\"\"\n",
    "    query_item = converted_dive_sites.loc[index, categories['name']].to_numpy()\n",
    "    return query_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dive_site_geodata_vector(index):\n",
    "    \"\"\"This function returns a vector representation of the geodata of the dive site with the given dive_site_id\"\"\"\n",
    "    query_item = converted_dive_sites.loc[index, ['lat_scaled', 'long_scaled']].to_numpy()\n",
    "    return query_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dive_site_animal_vector(index):\n",
    "    \"\"\"This function returns a vector representation of animals for the dive site with the given index.\"\"\"\n",
    "    query_item = converted_dive_sites.loc[index, animals['name']].to_numpy()\n",
    "    return query_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(dive_site_id, w_cat=1/3, w_geo=1/3, w_animal=1/3, n=10):\n",
    "    \"\"\"\n",
    "    This function generates a recommendation based on the category & geodata of the input dive site.\n",
    "\n",
    "    w_cat: weight for the category vector\n",
    "    w_geo: weight for the geodata (lat_scaled, long_scaled) vector \n",
    "    \"\"\"\n",
    "    print(f\"Generating recommendations for dive site with ID {dive_site_id}...\")\n",
    "\n",
    "    idx = indices[dive_site_id]\n",
    "\n",
    "    # Query Dive Site: Get Feature Vectors\n",
    "    # Category vector\n",
    "    query_categories_vector = query_dive_site_categories_vector(idx)\n",
    "    # Geodata vector\n",
    "    query_geodata_vector = query_dive_site_geodata_vector(idx)\n",
    "    # Animal vector\n",
    "    query_animal_vector = query_dive_site_animal_vector(idx)\n",
    "    \n",
    "    print(f\"Queried dive site index: {idx}\")\n",
    "\n",
    "    # compute cosine similarities between query dive site and all\n",
    "    # dive sites in the catalog (except for the query dive site)\n",
    "    similarities = []\n",
    "\n",
    "    # iterate over all dive sites\n",
    "    for i in range(len(converted_dive_sites[categories['name']])):\n",
    "        # skip the query item\n",
    "        if i != idx:\n",
    "\n",
    "            total_weight = 0\n",
    "            combined_similarity = 0\n",
    "\n",
    "            # Category Similarity\n",
    "            if w_cat > 0:\n",
    "                other_categories_vector = query_dive_site_categories_vector(i)\n",
    "                if np.count_nonzero(other_categories_vector) > 0:\n",
    "                    sim_cat = get_cosine_similarity(query_categories_vector, other_categories_vector)\n",
    "                    combined_similarity += w_cat * sim_cat\n",
    "                    total_weight += w_cat\n",
    "\n",
    "            # Geodata Similarity\n",
    "            if w_geo > 0:\n",
    "                other_geodata_vector = query_dive_site_geodata_vector(i)\n",
    "                if np.count_nonzero(other_geodata_vector) > 0:\n",
    "                    sim_geo = get_cosine_similarity(query_geodata_vector, other_geodata_vector)\n",
    "                    combined_similarity += w_geo * sim_geo\n",
    "                    total_weight += w_geo\n",
    "\n",
    "            # Animal Similarity\n",
    "            if w_animal > 0:\n",
    "                other_animal_vector = query_dive_site_animal_vector(i)\n",
    "                if np.count_nonzero(other_animal_vector) > 0:\n",
    "                    sim_animal = get_cosine_similarity(query_animal_vector, other_animal_vector)\n",
    "                    combined_similarity += w_animal * sim_animal\n",
    "                    total_weight += w_animal\n",
    "\n",
    "            # Normalize the similarity by total weight if any feature contributed\n",
    "            if total_weight > 0:\n",
    "                combined_similarity /= total_weight\n",
    "                similarities.append((i, combined_similarity))\n",
    "\n",
    "    # sort pairs w.r.t. second entry (cosine similarities) in \n",
    "    # descending order (reverse=True)\n",
    "    sorted_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # take the top n elements\n",
    "    sorted_similarities = sorted_similarities[:n]\n",
    "\n",
    "    # get the corresponding dive sites indices and similarities\n",
    "    dive_site_indices = [pair[0] for pair in sorted_similarities]\n",
    "    dive_site_similarities = [pair[1] for pair in sorted_similarities]\n",
    "\n",
    "    # log the similarities\n",
    "    for idx, sim in zip(dive_site_indices, dive_site_similarities):\n",
    "        print(f\"Dive site index: {idx}, Similarity: {sim}\")\n",
    "\n",
    "    # return the list of titles and similarities\n",
    "    recommendations = converted_dive_sites.loc[dive_site_indices]\n",
    "    recommendations[f'Similarity to dive spot {dive_site_id}'] = dive_site_similarities\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I asked for recommendations for dive site with ID 2:\n",
      "id                                                             2\n",
      "title                                     USAT Liberty Shipwreck\n",
      "lat                                                     -8.27396\n",
      "long                                                   115.59307\n",
      "description    This is probably the most famous dive site in ...\n",
      "occurences     Sea Turtle, Jackfish, Grouper, Dorid Nudibranc...\n",
      "categories                                    Wreck, Beach, Wall\n",
      "Name: 29, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# the following examples all use dive site with id = 2\n",
    "\n",
    "print(\"I asked for recommendations for dive site with ID 2:\")\n",
    "print(converted_dive_sites.loc[indices[2]][['id', 'title', 'lat', 'long', 'description', 'occurences', 'categories']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: General Recommendation\n",
    "\n",
    "Category, Location and Occurences are equally important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for dive site with ID 2...\n",
      "Queried dive site index: 29\n",
      "Dive site index: 4376, Similarity: 1.0\n",
      "Dive site index: 2863, Similarity: 0.9553418012614756\n",
      "Dive site index: 3251, Similarity: 0.8888888888731816\n",
      "Dive site index: 1088, Similarity: 0.8888888886322581\n",
      "Dive site index: 32, Similarity: 0.855124596410511\n",
      "Dive site index: 4380, Similarity: 0.855124596410511\n",
      "Dive site index: 4153, Similarity: 0.7563325626362134\n",
      "Dive site index: 2886, Similarity: 0.7374934089163421\n",
      "Dive site index: 706, Similarity: 0.7356511818922868\n",
      "Dive site index: 708, Similarity: 0.7328826448984018\n",
      "\n",
      "RESULT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Similarity to dive spot 2</th>\n",
       "      <th>occurences</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>4377</td>\n",
       "      <td>USAT Liberty Shipwreck</td>\n",
       "      <td>-8.27396</td>\n",
       "      <td>115.59307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mackerel, Cardinalfish, Butterflyfish, Gobies,...</td>\n",
       "      <td>Wreck, Beach, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>2859</td>\n",
       "      <td>Indonesia Bali Tulamben USS Liberty Wreck</td>\n",
       "      <td>-8.27397</td>\n",
       "      <td>115.59312</td>\n",
       "      <td>0.955342</td>\n",
       "      <td>Baracuda, Moray Eel, Saddleback Fish, Angelfis...</td>\n",
       "      <td>Wreck, Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>3248</td>\n",
       "      <td>自由号沉船</td>\n",
       "      <td>-8.27299</td>\n",
       "      <td>115.59239</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>Surgeonfish, Sea Turtle, Trumpetfish, Baracuda...</td>\n",
       "      <td>Wreck, Beach, Ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1070</td>\n",
       "      <td>Drop Off</td>\n",
       "      <td>-8.27779</td>\n",
       "      <td>115.59651</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>Saber-Toothed Blennies, Tigerfish, Butterflyfi...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>Tulamben</td>\n",
       "      <td>-8.27341</td>\n",
       "      <td>115.59235</td>\n",
       "      <td>0.855125</td>\n",
       "      <td>Jackfish, Goatfish, Cuttlefish, Seahorse Famil...</td>\n",
       "      <td>Wreck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>4381</td>\n",
       "      <td>Tulamben</td>\n",
       "      <td>-8.27341</td>\n",
       "      <td>115.59235</td>\n",
       "      <td>0.855125</td>\n",
       "      <td>Seahorse Family, Stingray, Cuttlefish, Scorpio...</td>\n",
       "      <td>Wreck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>4152</td>\n",
       "      <td>Wreck Point</td>\n",
       "      <td>13.52245</td>\n",
       "      <td>120.98470</td>\n",
       "      <td>0.756333</td>\n",
       "      <td>Snaper, Hawkfish, Baracuda, Tigerfish, Moray E...</td>\n",
       "      <td>Wreck, Drift, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>2883</td>\n",
       "      <td>Koh Tao</td>\n",
       "      <td>10.09225</td>\n",
       "      <td>99.83860</td>\n",
       "      <td>0.737493</td>\n",
       "      <td>Tigerfish, Hawksbill Turtle, Jackfish, Butterf...</td>\n",
       "      <td>Wreck, Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>684</td>\n",
       "      <td>Lighthouse</td>\n",
       "      <td>28.49902</td>\n",
       "      <td>34.51988</td>\n",
       "      <td>0.735651</td>\n",
       "      <td>Electric Ray, Snaper, Ghostpipefish, Stonefish...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>686</td>\n",
       "      <td>Mashraba</td>\n",
       "      <td>28.49520</td>\n",
       "      <td>34.51702</td>\n",
       "      <td>0.732883</td>\n",
       "      <td>Goatfish, Leptastrea Fish, Damselfish, Moray E...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                      title       lat       long  \\\n",
       "4376  4377                     USAT Liberty Shipwreck  -8.27396  115.59307   \n",
       "2863  2859  Indonesia Bali Tulamben USS Liberty Wreck  -8.27397  115.59312   \n",
       "3251  3248                                      自由号沉船  -8.27299  115.59239   \n",
       "1088  1070                                   Drop Off  -8.27779  115.59651   \n",
       "32       6                                   Tulamben  -8.27341  115.59235   \n",
       "4380  4381                                   Tulamben  -8.27341  115.59235   \n",
       "4153  4152                                Wreck Point  13.52245  120.98470   \n",
       "2886  2883                                    Koh Tao  10.09225   99.83860   \n",
       "706    684                                 Lighthouse  28.49902   34.51988   \n",
       "708    686                                   Mashraba  28.49520   34.51702   \n",
       "\n",
       "      Similarity to dive spot 2  \\\n",
       "4376                   1.000000   \n",
       "2863                   0.955342   \n",
       "3251                   0.888889   \n",
       "1088                   0.888889   \n",
       "32                     0.855125   \n",
       "4380                   0.855125   \n",
       "4153                   0.756333   \n",
       "2886                   0.737493   \n",
       "706                    0.735651   \n",
       "708                    0.732883   \n",
       "\n",
       "                                             occurences  \\\n",
       "4376  Mackerel, Cardinalfish, Butterflyfish, Gobies,...   \n",
       "2863  Baracuda, Moray Eel, Saddleback Fish, Angelfis...   \n",
       "3251  Surgeonfish, Sea Turtle, Trumpetfish, Baracuda...   \n",
       "1088  Saber-Toothed Blennies, Tigerfish, Butterflyfi...   \n",
       "32    Jackfish, Goatfish, Cuttlefish, Seahorse Famil...   \n",
       "4380  Seahorse Family, Stingray, Cuttlefish, Scorpio...   \n",
       "4153  Snaper, Hawkfish, Baracuda, Tigerfish, Moray E...   \n",
       "2886  Tigerfish, Hawksbill Turtle, Jackfish, Butterf...   \n",
       "706   Electric Ray, Snaper, Ghostpipefish, Stonefish...   \n",
       "708   Goatfish, Leptastrea Fish, Damselfish, Moray E...   \n",
       "\n",
       "                    categories  \n",
       "4376        Wreck, Beach, Wall  \n",
       "2863  Wreck, Beach, Reef, Wall  \n",
       "3251       Wreck, Beach, Ocean  \n",
       "1088         Beach, Reef, Wall  \n",
       "32                       Wreck  \n",
       "4380                     Wreck  \n",
       "4153  Wreck, Drift, Reef, Wall  \n",
       "2886  Wreck, Beach, Reef, Wall  \n",
       "706          Beach, Reef, Wall  \n",
       "708          Beach, Reef, Wall  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_recommendations = get_recommendations(2, w_cat=1/3, w_geo=1/3, w_animal=1/3, n=10)\n",
    "\n",
    "print(\"\\nRESULT\")\n",
    "example_recommendations[['id', 'title', 'lat', 'long', 'Similarity to dive spot 2', 'occurences', 'categories']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Only look at geographically close dive sites to id=2. Ignore animals and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for dive site with ID 2...\n",
      "Queried dive site index: 29\n",
      "Dive site index: 4376, Similarity: 0.9999999999999999\n",
      "Dive site index: 2863, Similarity: 0.9999999999999883\n",
      "Dive site index: 32, Similarity: 0.9999999999825536\n",
      "Dive site index: 4380, Similarity: 0.9999999999825536\n",
      "Dive site index: 3251, Similarity: 0.9999999999528784\n",
      "Dive site index: 1088, Similarity: 0.9999999992301077\n",
      "Dive site index: 3241, Similarity: 0.9999999964022446\n",
      "Dive site index: 1059, Similarity: 0.9999999935508563\n",
      "Dive site index: 1118, Similarity: 0.9999999715228576\n",
      "Dive site index: 1360, Similarity: 0.9999998185603852\n",
      "\n",
      "RESULT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Similarity to dive spot 2</th>\n",
       "      <th>occurences</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>4377</td>\n",
       "      <td>USAT Liberty Shipwreck</td>\n",
       "      <td>-8.27396</td>\n",
       "      <td>115.59307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mackerel, Cardinalfish, Butterflyfish, Gobies,...</td>\n",
       "      <td>Wreck, Beach, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>2859</td>\n",
       "      <td>Indonesia Bali Tulamben USS Liberty Wreck</td>\n",
       "      <td>-8.27397</td>\n",
       "      <td>115.59312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Baracuda, Moray Eel, Saddleback Fish, Angelfis...</td>\n",
       "      <td>Wreck, Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>Tulamben</td>\n",
       "      <td>-8.27341</td>\n",
       "      <td>115.59235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jackfish, Goatfish, Cuttlefish, Seahorse Famil...</td>\n",
       "      <td>Wreck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>4381</td>\n",
       "      <td>Tulamben</td>\n",
       "      <td>-8.27341</td>\n",
       "      <td>115.59235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seahorse Family, Stingray, Cuttlefish, Scorpio...</td>\n",
       "      <td>Wreck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>3248</td>\n",
       "      <td>自由号沉船</td>\n",
       "      <td>-8.27299</td>\n",
       "      <td>115.59239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Surgeonfish, Sea Turtle, Trumpetfish, Baracuda...</td>\n",
       "      <td>Wreck, Beach, Ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1070</td>\n",
       "      <td>Drop Off</td>\n",
       "      <td>-8.27779</td>\n",
       "      <td>115.59651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Saber-Toothed Blennies, Tigerfish, Butterflyfi...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>3238</td>\n",
       "      <td>house reff</td>\n",
       "      <td>-8.26530</td>\n",
       "      <td>115.58853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Baracuda, Parrotfish, Saddleback Fish, Grouper...</td>\n",
       "      <td>Beach, Reef, Sea Loch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1042</td>\n",
       "      <td>Tulamben Area (Seraya, Sidem)</td>\n",
       "      <td>-8.28477</td>\n",
       "      <td>115.60512</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1099</td>\n",
       "      <td>Kubu, Boga Wreck</td>\n",
       "      <td>-8.24955</td>\n",
       "      <td>115.58064</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Wreck, Reef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1342</td>\n",
       "      <td>Melasti</td>\n",
       "      <td>-8.33331</td>\n",
       "      <td>115.64163</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                      title      lat       long  \\\n",
       "4376  4377                     USAT Liberty Shipwreck -8.27396  115.59307   \n",
       "2863  2859  Indonesia Bali Tulamben USS Liberty Wreck -8.27397  115.59312   \n",
       "32       6                                   Tulamben -8.27341  115.59235   \n",
       "4380  4381                                   Tulamben -8.27341  115.59235   \n",
       "3251  3248                                      自由号沉船 -8.27299  115.59239   \n",
       "1088  1070                                   Drop Off -8.27779  115.59651   \n",
       "3241  3238                                 house reff -8.26530  115.58853   \n",
       "1059  1042              Tulamben Area (Seraya, Sidem) -8.28477  115.60512   \n",
       "1118  1099                           Kubu, Boga Wreck -8.24955  115.58064   \n",
       "1360  1342                                    Melasti -8.33331  115.64163   \n",
       "\n",
       "      Similarity to dive spot 2  \\\n",
       "4376                        1.0   \n",
       "2863                        1.0   \n",
       "32                          1.0   \n",
       "4380                        1.0   \n",
       "3251                        1.0   \n",
       "1088                        1.0   \n",
       "3241                        1.0   \n",
       "1059                        1.0   \n",
       "1118                        1.0   \n",
       "1360                        1.0   \n",
       "\n",
       "                                             occurences  \\\n",
       "4376  Mackerel, Cardinalfish, Butterflyfish, Gobies,...   \n",
       "2863  Baracuda, Moray Eel, Saddleback Fish, Angelfis...   \n",
       "32    Jackfish, Goatfish, Cuttlefish, Seahorse Famil...   \n",
       "4380  Seahorse Family, Stingray, Cuttlefish, Scorpio...   \n",
       "3251  Surgeonfish, Sea Turtle, Trumpetfish, Baracuda...   \n",
       "1088  Saber-Toothed Blennies, Tigerfish, Butterflyfi...   \n",
       "3241  Baracuda, Parrotfish, Saddleback Fish, Grouper...   \n",
       "1059                                                      \n",
       "1118                                                      \n",
       "1360                                                      \n",
       "\n",
       "                    categories  \n",
       "4376        Wreck, Beach, Wall  \n",
       "2863  Wreck, Beach, Reef, Wall  \n",
       "32                       Wreck  \n",
       "4380                     Wreck  \n",
       "3251       Wreck, Beach, Ocean  \n",
       "1088         Beach, Reef, Wall  \n",
       "3241     Beach, Reef, Sea Loch  \n",
       "1059                     Beach  \n",
       "1118               Wreck, Reef  \n",
       "1360                     Beach  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_recommendations = get_recommendations(2, w_cat=0, w_geo=1, w_animal=0, n=10)\n",
    "\n",
    "print(\"\\nRESULT\")\n",
    "example_recommendations[['id', 'title', 'lat', 'long', 'Similarity to dive spot 2', 'occurences', 'categories']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Get similar dive site regardless of distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for dive site with ID 2...\n",
      "Queried dive site index: 29\n",
      "Dive site index: 4376, Similarity: 1.0\n",
      "Dive site index: 2863, Similarity: 0.9330127018922194\n",
      "Dive site index: 1088, Similarity: 0.8333333333333334\n",
      "Dive site index: 3251, Similarity: 0.8333333333333334\n",
      "Dive site index: 32, Similarity: 0.7826868946244898\n",
      "Dive site index: 4380, Similarity: 0.7826868946244898\n",
      "Dive site index: 706, Similarity: 0.6542684370602689\n",
      "Dive site index: 708, Similarity: 0.6501115397424062\n",
      "Dive site index: 4153, Similarity: 0.6420978456823869\n",
      "Dive site index: 2886, Similarity: 0.6144702155649595\n",
      "\n",
      "RESULT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Similarity to dive spot 2</th>\n",
       "      <th>occurences</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>4377</td>\n",
       "      <td>USAT Liberty Shipwreck</td>\n",
       "      <td>-8.27396</td>\n",
       "      <td>115.59307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mackerel, Cardinalfish, Butterflyfish, Gobies,...</td>\n",
       "      <td>Wreck, Beach, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>2859</td>\n",
       "      <td>Indonesia Bali Tulamben USS Liberty Wreck</td>\n",
       "      <td>-8.27397</td>\n",
       "      <td>115.59312</td>\n",
       "      <td>0.933013</td>\n",
       "      <td>Baracuda, Moray Eel, Saddleback Fish, Angelfis...</td>\n",
       "      <td>Wreck, Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1070</td>\n",
       "      <td>Drop Off</td>\n",
       "      <td>-8.27779</td>\n",
       "      <td>115.59651</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Saber-Toothed Blennies, Tigerfish, Butterflyfi...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>3248</td>\n",
       "      <td>自由号沉船</td>\n",
       "      <td>-8.27299</td>\n",
       "      <td>115.59239</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Surgeonfish, Sea Turtle, Trumpetfish, Baracuda...</td>\n",
       "      <td>Wreck, Beach, Ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>Tulamben</td>\n",
       "      <td>-8.27341</td>\n",
       "      <td>115.59235</td>\n",
       "      <td>0.782687</td>\n",
       "      <td>Jackfish, Goatfish, Cuttlefish, Seahorse Famil...</td>\n",
       "      <td>Wreck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>4381</td>\n",
       "      <td>Tulamben</td>\n",
       "      <td>-8.27341</td>\n",
       "      <td>115.59235</td>\n",
       "      <td>0.782687</td>\n",
       "      <td>Seahorse Family, Stingray, Cuttlefish, Scorpio...</td>\n",
       "      <td>Wreck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>684</td>\n",
       "      <td>Lighthouse</td>\n",
       "      <td>28.49902</td>\n",
       "      <td>34.51988</td>\n",
       "      <td>0.654268</td>\n",
       "      <td>Electric Ray, Snaper, Ghostpipefish, Stonefish...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>686</td>\n",
       "      <td>Mashraba</td>\n",
       "      <td>28.49520</td>\n",
       "      <td>34.51702</td>\n",
       "      <td>0.650112</td>\n",
       "      <td>Goatfish, Leptastrea Fish, Damselfish, Moray E...</td>\n",
       "      <td>Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>4152</td>\n",
       "      <td>Wreck Point</td>\n",
       "      <td>13.52245</td>\n",
       "      <td>120.98470</td>\n",
       "      <td>0.642098</td>\n",
       "      <td>Snaper, Hawkfish, Baracuda, Tigerfish, Moray E...</td>\n",
       "      <td>Wreck, Drift, Reef, Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>2883</td>\n",
       "      <td>Koh Tao</td>\n",
       "      <td>10.09225</td>\n",
       "      <td>99.83860</td>\n",
       "      <td>0.614470</td>\n",
       "      <td>Tigerfish, Hawksbill Turtle, Jackfish, Butterf...</td>\n",
       "      <td>Wreck, Beach, Reef, Wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                      title       lat       long  \\\n",
       "4376  4377                     USAT Liberty Shipwreck  -8.27396  115.59307   \n",
       "2863  2859  Indonesia Bali Tulamben USS Liberty Wreck  -8.27397  115.59312   \n",
       "1088  1070                                   Drop Off  -8.27779  115.59651   \n",
       "3251  3248                                      自由号沉船  -8.27299  115.59239   \n",
       "32       6                                   Tulamben  -8.27341  115.59235   \n",
       "4380  4381                                   Tulamben  -8.27341  115.59235   \n",
       "706    684                                 Lighthouse  28.49902   34.51988   \n",
       "708    686                                   Mashraba  28.49520   34.51702   \n",
       "4153  4152                                Wreck Point  13.52245  120.98470   \n",
       "2886  2883                                    Koh Tao  10.09225   99.83860   \n",
       "\n",
       "      Similarity to dive spot 2  \\\n",
       "4376                   1.000000   \n",
       "2863                   0.933013   \n",
       "1088                   0.833333   \n",
       "3251                   0.833333   \n",
       "32                     0.782687   \n",
       "4380                   0.782687   \n",
       "706                    0.654268   \n",
       "708                    0.650112   \n",
       "4153                   0.642098   \n",
       "2886                   0.614470   \n",
       "\n",
       "                                             occurences  \\\n",
       "4376  Mackerel, Cardinalfish, Butterflyfish, Gobies,...   \n",
       "2863  Baracuda, Moray Eel, Saddleback Fish, Angelfis...   \n",
       "1088  Saber-Toothed Blennies, Tigerfish, Butterflyfi...   \n",
       "3251  Surgeonfish, Sea Turtle, Trumpetfish, Baracuda...   \n",
       "32    Jackfish, Goatfish, Cuttlefish, Seahorse Famil...   \n",
       "4380  Seahorse Family, Stingray, Cuttlefish, Scorpio...   \n",
       "706   Electric Ray, Snaper, Ghostpipefish, Stonefish...   \n",
       "708   Goatfish, Leptastrea Fish, Damselfish, Moray E...   \n",
       "4153  Snaper, Hawkfish, Baracuda, Tigerfish, Moray E...   \n",
       "2886  Tigerfish, Hawksbill Turtle, Jackfish, Butterf...   \n",
       "\n",
       "                    categories  \n",
       "4376        Wreck, Beach, Wall  \n",
       "2863  Wreck, Beach, Reef, Wall  \n",
       "1088         Beach, Reef, Wall  \n",
       "3251       Wreck, Beach, Ocean  \n",
       "32                       Wreck  \n",
       "4380                     Wreck  \n",
       "706          Beach, Reef, Wall  \n",
       "708          Beach, Reef, Wall  \n",
       "4153  Wreck, Drift, Reef, Wall  \n",
       "2886  Wreck, Beach, Reef, Wall  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also insert negative weights, e.g. w_geo = -1 to punish recommendations that are close geographically\n",
    "\n",
    "# Example: Punish recommendations that are close to the query dive site\n",
    "example_recommendations = get_recommendations(2, w_cat=0.5, w_geo=0, w_animal=0.5, n=10)\n",
    "\n",
    "print(\"\\nRESULT\")\n",
    "example_recommendations[['id', 'title', 'lat', 'long', 'Similarity to dive spot 2', 'occurences', 'categories']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Find dive sites with a similar profile, prioritise result that are far away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for dive site with ID 2...\n",
      "Queried dive site index: 29\n",
      "Dive site index: 1060, Similarity: -1.6449333590935766\n",
      "Dive site index: 1949, Similarity: -1.7205489899960948\n",
      "Dive site index: 2724, Similarity: -1.7571021152022004\n",
      "Dive site index: 3246, Similarity: -1.7730867639710242\n",
      "Dive site index: 2692, Similarity: -1.7731602488549787\n",
      "Dive site index: 3942, Similarity: -1.8055631700594117\n",
      "Dive site index: 2689, Similarity: -1.8238865639470645\n",
      "Dive site index: 3952, Similarity: -1.8494810226802638\n",
      "Dive site index: 2687, Similarity: -1.8542775859241922\n",
      "Dive site index: 2688, Similarity: -1.8666992885874463\n",
      "\n",
      "RESULT\n",
      "        id               title       lat       long  \\\n",
      "1060  1043           Sea Tiger  21.28865 -157.87070   \n",
      "1949  1949     Sea Tiger Wreck  21.27071 -157.83860   \n",
      "2724  2715  Molokini Back Wall  20.63066 -156.49477   \n",
      "3246  3243      Electric beach  21.35404 -158.13054   \n",
      "2692  2685          Mala Wharf  20.88608 -156.68760   \n",
      "3942  3941       Coral Nursery -19.12717 -169.91541   \n",
      "2689  2682         Honolua Bay  21.01397 -156.63822   \n",
      "3952  3950            Wormhole -19.06340 -169.93568   \n",
      "2687  2680          Black Rock  20.92765 -156.69693   \n",
      "2688  2681       Airport Beach  20.93603 -156.69293   \n",
      "\n",
      "      Similarity to dive spot 2  \\\n",
      "1060                  -1.644933   \n",
      "1949                  -1.720549   \n",
      "2724                  -1.757102   \n",
      "3246                  -1.773087   \n",
      "2692                  -1.773160   \n",
      "3942                  -1.805563   \n",
      "2689                  -1.823887   \n",
      "3952                  -1.849481   \n",
      "2687                  -1.854278   \n",
      "2688                  -1.866699   \n",
      "\n",
      "                                             occurences  \\\n",
      "1060  Butterflyfish, Surgeonfish, Needlefish, Puffer...   \n",
      "1949  Sea Turtle, Goatfish, Tigerfish, Moray Eel, Wr...   \n",
      "2724  Starfish, Rorquals, Tigerfish, Dorid Nudibranc...   \n",
      "3246  Houndsharks, Trumpetfish, Grouper, Sea Turtle,...   \n",
      "2692  Sea Turtle, Frogfish, Moray Eel, Requiem Shark...   \n",
      "3942                Gray Reef Shark, Crawfish, Baracuda   \n",
      "2689  Butterflyfish, Trumpetfish Pipefish, Surgeonfi...   \n",
      "3952                        Nudibranch, Clam, Sea Snake   \n",
      "2687  Green Turtles, Snaper, Requiem Sharks, Opah, S...   \n",
      "2688  Opah, Tigerfish, Requiem Sharks, Scorpionfish,...   \n",
      "\n",
      "                                   categories  \n",
      "1060                                    Wreck  \n",
      "1949                             Wreck, Ocean  \n",
      "2724                       Drift, Wall, Ocean  \n",
      "3246         Beach, Reef, Sandy bottom, Ocean  \n",
      "2692  Wreck, Beach, Reef, Sandy bottom, Ocean  \n",
      "3942                                     Reef  \n",
      "2689                Beach, Reef, Sandy bottom  \n",
      "3952                               Cave, Reef  \n",
      "2687   Drift, Reef, Sandy bottom, Wall, Ocean  \n",
      "2688         Beach, Reef, Sandy bottom, Ocean  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: Punish recommendations that are close to the query dive site\n",
    "example_recommendations = get_recommendations(2, w_cat=0.5, w_geo=-5, w_animal=0.5, n=10)\n",
    "\n",
    "print(\"\\nRESULT\")\n",
    "example_recommendations[['id', 'title', 'lat', 'long', 'Similarity to dive spot 2', 'occurences', 'categories']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
